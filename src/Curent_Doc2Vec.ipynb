{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manny/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/manny/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/manny/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      " 58%|█████▊    | 11/19 [00:32<00:23,  3.00s/it]"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from pddoc2vec import doc2vec\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "client = MongoClient()\n",
    "client = MongoClient('localhost', 27017)  #Connects to the MongoDB, make sure youre SSH'ed into the docker\n",
    "\n",
    "collection_list = client['twitter'].collection_names() #Scrapes all the collection names from the Docker\n",
    "\n",
    "sentimentdata = []\n",
    "for posts in tqdm(collection_list):\n",
    "    for post in client['twitter'][posts].find({'sentiment': {\"$exists\": True}}):  #Extracts all the entries with a sentiment field\n",
    "        post.update({\"Source\": str(posts)}) #Updates each data with the name of the collection it comes from\n",
    "        sentimentdata.append(post) \n",
    "\n",
    "df = pd.DataFrame(sentimentdata) # pulls data into the Pandas DataFrame\n",
    "\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.values) #How many Columns we have in our dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Source'].value_counts() \n",
    "\n",
    "#How many sources our data comes from,  different sources might label the \n",
    "#same data under different names/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df['Source'] == 'Misc_MiscFilmReviews_M'].sample(4))\n",
    "\n",
    "# This source contains the text under \"text\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[df['Source'] == 'LabeledStatuses_Sandy_K'].sample(4))\n",
    "\n",
    "# This source contains the text under \"TweetBody\" and has a \"classification\"\n",
    "# field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"main\"] = df[\"sentiment\"]\n",
    "# we are going to build a main label that is just the sentiment\n",
    "\n",
    "df[\"sentiment\"] = df[\"Source\"] + \"_\" + df[\"sentiment\"]\n",
    "# We add source informationg with the sentiment\n",
    "\n",
    "df['text'].fillna(df['TweetBody'], inplace=True)\n",
    "# we move the text from tweetbody into text\n",
    "\n",
    "df['classification'] = df['classification'].fillna(\"0\")\n",
    "#we populate empty classification  fields with \"0\"\n",
    "\n",
    "\n",
    "print(df.isna().sum())\n",
    "\n",
    "df = df.applymap(str)\n",
    "print(df.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building model\")\n",
    "\n",
    "# We pass the class 3 fields:\n",
    "# 1. The DataFrame\n",
    "# 2. The X value, the Text (Pandas Series)\n",
    "# 3. The Y values, the labels that correspond to the text (Pandas Series)\n",
    "#                   It can be a list of the names of the columns or one as a string\n",
    "\n",
    "x = doc2vec(df, \"text\", [\"main\",  \"Source\", 'sentiment', 'classification'])\n",
    "\n",
    "\n",
    "print(\"Scoring Model\")\n",
    "\n",
    "#returns scores of each labels accuracy from the first column passed into \n",
    "# the Y or 3 arguments, in this example it was \"main\"\n",
    "# this uses sklearn.metrics.f1_score, you can pass in \n",
    "print(x.score())\n",
    "\n",
    "print(\"Predicting on text\")\n",
    "\n",
    "# You can predict text as follows\n",
    "print(x.predict_text(\"its going to be the worst time ever\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to save model https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "x.model.save(fname)\n",
    "x.model = Doc2Vec.load(fname)  # you can continue training with the loaded model!\n",
    "\n",
    "# If you’re finished training a model (=no more updates, only querying, reduce memory usage), you can do:\n",
    "\n",
    "x.model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
