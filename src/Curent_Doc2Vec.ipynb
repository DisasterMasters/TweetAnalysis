{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manny/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/manny/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/manny/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: collection_names is deprecated. Use list_collection_names instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "100%|██████████| 19/19 [11:11<00:00, 35.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Lat_long                   Source  \\\n",
      "0        |  LabeledStatuses_Sandy_K   \n",
      "1        |  LabeledStatuses_Sandy_K   \n",
      "2        |  LabeledStatuses_Sandy_K   \n",
      "3        |  LabeledStatuses_Sandy_K   \n",
      "4        |  LabeledStatuses_Sandy_K   \n",
      "5        |  LabeledStatuses_Sandy_K   \n",
      "6        |  LabeledStatuses_Sandy_K   \n",
      "7        |  LabeledStatuses_Sandy_K   \n",
      "8        |  LabeledStatuses_Sandy_K   \n",
      "9        |  LabeledStatuses_Sandy_K   \n",
      "\n",
      "                                           TweetBody                TweetID  \\\n",
      "0  -1 RT @_dreamvillle: On a scale from 1-5 how s...  |\"261938696272629761\"   \n",
      "1  @jenfromTHEbloc Hi! I have you and all your NY...  |\"261964535831871488\"   \n",
      "2  #Pakistan Salesforce Social Marketing Cloud Bu...  |\"261985749170270208\"   \n",
      "3  Frankenstorm heads toward US East Coast: Hurri...  |\"262095362175684609\"   \n",
      "4  5 reasons why Sandy is expected to be a supers...  |\"262227769931493376\"   \n",
      "5  Hurricane Sandy is hitting Chick Fil A hard - ...  |\"262235426356596736\"   \n",
      "6  If this storm come next week <<<< if its no sc...  |\"262239836457545729\"   \n",
      "7  RT @NBCConnecticut: Malloy will fully activate...  |\"262258318133821440\"   \n",
      "8  RT @NBCConnecticut: Malloy: Everyone is in dan...  |\"262268521101279232\"   \n",
      "9  \"@Dankula This is all I need for the storm!! h...  |\"262304338985230336\"   \n",
      "\n",
      "            UserID                       _id  classification  \\\n",
      "0           man_EE  5c0e7b47d2512c61248b14c5  conversational   \n",
      "1  xGrumpyOlTrollx  5c0e7b47d2512c61248b14c6  conversational   \n",
      "2        22FOURCOM  5c0e7b47d2512c61248b14c7      irrelevant   \n",
      "3      MuthuKrish7  5c0e7b47d2512c61248b14c8  conversational   \n",
      "4    Seahawks_Sigs  5c0e7b47d2512c61248b14c9  conversational   \n",
      "5          ssjarvs  5c0e7b47d2512c61248b14ca  conversational   \n",
      "6     CamP_Knights  5c0e7b47d2512c61248b14cb  conversational   \n",
      "7     SunnyLuciani  5c0e7b47d2512c61248b14cc   informational   \n",
      "8         JockinGC  5c0e7b47d2512c61248b14cd  conversational   \n",
      "9       BiggGrizzz  5c0e7b47d2512c61248b14ce  conversational   \n",
      "\n",
      "          date_time notes                      original_file   sentiment text  \n",
      "0  10/26/2012 21:13        LABELED_DATA/ClassifiedTweets.csv    positive  NaN  \n",
      "1  10/26/2012 22:56        LABELED_DATA/ClassifiedTweets.csv    positive  NaN  \n",
      "2   10/27/2012 0:20        LABELED_DATA/ClassifiedTweets.csv  irrelevant  NaN  \n",
      "3   10/27/2012 7:36        LABELED_DATA/ClassifiedTweets.csv    negative  NaN  \n",
      "4  10/27/2012 16:22        LABELED_DATA/ClassifiedTweets.csv    negative  NaN  \n",
      "5  10/27/2012 16:52        LABELED_DATA/ClassifiedTweets.csv    negative  NaN  \n",
      "6  10/27/2012 17:10        LABELED_DATA/ClassifiedTweets.csv    positive  NaN  \n",
      "7  10/27/2012 18:23        LABELED_DATA/ClassifiedTweets.csv     neutral  NaN  \n",
      "8  10/27/2012 19:04        LABELED_DATA/ClassifiedTweets.csv    negative  NaN  \n",
      "9  10/27/2012 21:26        LABELED_DATA/ClassifiedTweets.csv    positive  NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from pd_doc2vec import doc2vec\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "client = MongoClient()\n",
    "client = MongoClient('localhost', 27017) \n",
    "#Connects to the MongoDB, make sure youre SSH'ed into the docker\n",
    "\n",
    "collection_list = client['twitter'].collection_names() \n",
    "#Scrapes all the collection names from the Docker\n",
    "\n",
    "sentimentdata = []\n",
    "for posts in tqdm(collection_list):\n",
    "    for post in client['twitter'][posts].find({'sentiment': {\"$exists\": True}}):  \n",
    "        #Extracts all the entries with a sentiment field\n",
    "        post.update({\"Source\": str(posts)}) \n",
    "        #Updates each data with the name of the collection it comes from\n",
    "        sentimentdata.append(post) \n",
    "\n",
    "df = pd.DataFrame(sentimentdata)\n",
    "# pulls data into the Pandas DataFrame\n",
    "\n",
    "\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lat_long' 'Source' 'TweetBody' 'TweetID' 'UserID' '_id' 'classification'\n",
      " 'date_time' 'notes' 'original_file' 'sentiment' 'text']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values) #How many Columns we have in our dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Misc_MiscFilmReviews_M     100000\n",
       "LabeledStatuses_Sandy_K       325\n",
       "Name: Source, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['Source'].value_counts() \n",
    "\n",
    "#How many sources our data comes from,  different sources might label the \n",
    "#same data under different names/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Lat_long                  Source TweetBody TweetID UserID  \\\n",
      "45179      NaN  Misc_MiscFilmReviews_M       NaN     NaN    NaN   \n",
      "52630      NaN  Misc_MiscFilmReviews_M       NaN     NaN    NaN   \n",
      "94812      NaN  Misc_MiscFilmReviews_M       NaN     NaN    NaN   \n",
      "59330      NaN  Misc_MiscFilmReviews_M       NaN     NaN    NaN   \n",
      "\n",
      "                            _id classification date_time notes original_file  \\\n",
      "45179  5beee74b8d75df321cfe78c7            NaN       NaN   NaN           NaN   \n",
      "52630  5beee7988d75df32fe7c3aa1            NaN       NaN   NaN           NaN   \n",
      "94812  5beee7988d75df32fe7cdf67            NaN       NaN   NaN           NaN   \n",
      "59330  5beee7988d75df32fe7c54cd            NaN       NaN   NaN           NaN   \n",
      "\n",
      "      sentiment                                               text  \n",
      "45179  negative  the story of a woman ann on her death bed her ...  \n",
      "52630  positive  this movie is based on the true story of iowa ...  \n",
      "94812  negative  rex reed once said of a movie julia and julia ...  \n",
      "59330  positive  to me anatomie is certainly one of the better ...  \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['Source'] == 'Misc_MiscFilmReviews_M'].sample(4))\n",
    "\n",
    "# This source contains the text under \"text\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Lat_long                   Source  \\\n",
      "215        |  LabeledStatuses_Sandy_K   \n",
      "150        |  LabeledStatuses_Sandy_K   \n",
      "93         |  LabeledStatuses_Sandy_K   \n",
      "5          |  LabeledStatuses_Sandy_K   \n",
      "\n",
      "                                             TweetBody                TweetID  \\\n",
      "215  RT @EarlDibblesJr: Hurricane Sandy aint nothin...  |\"263694939572027392\"   \n",
      "150  Before you RT #photos â†’That amazing #Sandy p...  |\"263042770384605185\"   \n",
      "93   RT @NotBranden: NYC/east coast: If cell networ...  |\"262958230118989824\"   \n",
      "5    Hurricane Sandy is hitting Chick Fil A hard - ...  |\"262235426356596736\"   \n",
      "\n",
      "          UserID                       _id  classification         date_time  \\\n",
      "215  GrantDominy  5c0e7b47d2512c61248b159c  conversational  10/31/2012 17:32   \n",
      "150   Care_Aware  5c0e7b47d2512c61248b155b  conversational  10/29/2012 22:20   \n",
      "93    WolfManNYI  5c0e7b47d2512c61248b1522   informational  10/29/2012 16:45   \n",
      "5        ssjarvs  5c0e7b47d2512c61248b14ca  conversational  10/27/2012 16:52   \n",
      "\n",
      "    notes                      original_file sentiment text  \n",
      "215        LABELED_DATA/ClassifiedTweets.csv  positive  NaN  \n",
      "150        LABELED_DATA/ClassifiedTweets.csv   neutral  NaN  \n",
      "93         LABELED_DATA/ClassifiedTweets.csv   neutral  NaN  \n",
      "5          LABELED_DATA/ClassifiedTweets.csv  negative  NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.loc[df['Source'] == 'LabeledStatuses_Sandy_K'].sample(4))\n",
    "\n",
    "# This source contains the text under \"TweetBody\" and has a \"classification\"\n",
    "# field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lat_long          100000\n",
      "Source                 0\n",
      "TweetBody         100000\n",
      "TweetID           100000\n",
      "UserID            100000\n",
      "_id                    0\n",
      "classification         0\n",
      "date_time         100000\n",
      "notes             100000\n",
      "original_file     100000\n",
      "sentiment              0\n",
      "text                   0\n",
      "main                   0\n",
      "dtype: int64\n",
      "Lat_long          0\n",
      "Source            0\n",
      "TweetBody         0\n",
      "TweetID           0\n",
      "UserID            0\n",
      "_id               0\n",
      "classification    0\n",
      "date_time         0\n",
      "notes             0\n",
      "original_file     0\n",
      "sentiment         0\n",
      "text              0\n",
      "main              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df[\"main\"] = df[\"sentiment\"]\n",
    "# we are going to build a main label that is just the sentiment\n",
    "\n",
    "df[\"sentiment\"] = df[\"Source\"] + \"_\" + df[\"sentiment\"]\n",
    "# We add source informationg with the sentiment\n",
    "\n",
    "df['text'].fillna(df['TweetBody'], inplace=True)\n",
    "# we move the text from tweetbody into text\n",
    "\n",
    "df['classification'] = df['classification'].fillna(\"0\")\n",
    "#we populate empty classification  fields with \"0\"\n",
    "\n",
    "\n",
    "print(df.isna().sum())\n",
    "\n",
    "df = df.applymap(str)\n",
    "print(df.isna().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building model\")\n",
    "\n",
    "# We pass the class 3 fields:\n",
    "# 1. The DataFrame\n",
    "# 2. The X value, the Text (Pandas Series)\n",
    "# 3. The Y values, the labels that correspond to the text (Pandas Series)\n",
    "#                   It can be a list of the names of the columns or one as a string\n",
    "\n",
    "x = doc2vec(df.sample(100), \"text\", [\"main\",  \"Source\", 'sentiment', 'classification'])\n",
    "\n",
    "\n",
    "print(\"Scoring Model\")\n",
    "\n",
    "#returns scores of each labels accuracy from the first column passed into \n",
    "# the Y or 3 arguments, in this example it was \"main\"\n",
    "# this uses sklearn.metrics.f1_score, you can pass in \n",
    "print(x.score())\n",
    "\n",
    "print(\"Predicting on text\")\n",
    "\n",
    "# You can predict text as follows\n",
    "print(x.predict_text(\"its going to be the worst time ever\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to save model from https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "x.model.save(fname)\n",
    "x.model = Doc2Vec.load(fname)  # you can continue training with the loaded model!\n",
    "\n",
    "# If you’re finished training a model (=no more updates, only querying, reduce memory usage), you can do:\n",
    "\n",
    "x.model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
